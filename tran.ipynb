{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "699a9156",
   "metadata": {},
   "source": [
    "### 環境設置與資料載入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e73d9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# 檢查CUDA可用性\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 資料路徑\n",
    "DATA_PATH = './train/'\n",
    "class_names = sorted(os.listdir(DATA_PATH))  # 獲取30個食物類別名稱\n",
    "\n",
    "# 建立類別到索引的映射\n",
    "class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50ad498",
   "metadata": {},
   "source": [
    "### 強化版資料增強"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c24d0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設計強化版資料增強管道\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 自定義MixUp和CutMix資料增強操作\n",
    "cutmix = v2.CutMix(num_classes=len(class_names))\n",
    "mixup = v2.MixUp(num_classes=len(class_names))\n",
    "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])\n",
    "\n",
    "# 自定義資料增強collate函數\n",
    "def collate_fn(batch):\n",
    "    return cutmix_or_mixup(*torch.utils.data.default_collate(batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781aa434",
   "metadata": {},
   "source": [
    "### 自定義資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eda5a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, root_dir, class_to_idx, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "        self.samples = self._make_dataset()\n",
    "        \n",
    "    def _make_dataset(self):\n",
    "        samples = []\n",
    "        for class_name in sorted(os.listdir(self.root_dir)):\n",
    "            class_dir = os.path.join(self.root_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        img_path = os.path.join(class_dir, img_name)\n",
    "                        samples.append((img_path, self.class_to_idx[class_name]))\n",
    "        return samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc7cd7",
   "metadata": {},
   "source": [
    "### MobileNetV2基礎模型設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4a7fa2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenetv2(num_classes=30):\n",
    "    # 載入預訓練的MobileNetV2\n",
    "    model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "    \n",
    "    # 凍結特徵提取層\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # 替換分類頭\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c15770",
   "metadata": {},
   "source": [
    "### Bayesian MAML實現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f38d45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianMAML:\n",
    "    def __init__(self, model, n_way=5, k_shot=5, num_particles=10, inner_lr=0.01, meta_lr=0.001):\n",
    "        self.model = model\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.num_particles = num_particles\n",
    "        self.inner_lr = inner_lr\n",
    "        self.meta_optimizer = optim.Adam(model.parameters(), lr=meta_lr)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # 初始化粒子集\n",
    "        self.particles = self._clone_particles(model)\n",
    "    \n",
    "    def _clone_particles(self, model):\n",
    "        \"\"\"複製模型參數生成多個粒子\"\"\"\n",
    "        particles = []\n",
    "        for _ in range(self.num_particles):\n",
    "            particle = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "            particles.append(particle)\n",
    "        return particles\n",
    "    \n",
    "    def _stein_gradient(self, particles, support_x, support_y, query_x, query_y):\n",
    "        \"\"\"計算Stein變分梯度下降(SVGD)的梯度\"\"\"\n",
    "        n = len(particles)\n",
    "        gradients = []\n",
    "        losses = []\n",
    "        \n",
    "        # 僅選擇需要梯度的參數\n",
    "        trainable_params = [p for p in self.model.parameters() if p.requires_grad]\n",
    "        \n",
    "        for particle in particles:\n",
    "            # 載入粒子參數\n",
    "            self.model.load_state_dict(particle)\n",
    "            \n",
    "            # 內循環更新（Fast adaptation）\n",
    "            self.model.train()\n",
    "            support_logits = self.model(support_x)\n",
    "            support_loss = self.loss_fn(support_logits, support_y)\n",
    "            grads = torch.autograd.grad(support_loss, trainable_params, create_graph=True)\n",
    "            \n",
    "            # 在查詢集上計算損失\n",
    "            query_logits = self.model(query_x)\n",
    "            query_loss = self.loss_fn(query_logits, query_y)\n",
    "            losses.append(query_loss)\n",
    "            \n",
    "            # 計算元梯度\n",
    "            meta_grads = torch.autograd.grad(query_loss, trainable_params, create_graph=True)\n",
    "            gradients.append(meta_grads)\n",
    "        \n",
    "        # 計算平均損失\n",
    "        avg_loss = torch.stack(losses).mean()\n",
    "        \n",
    "        # 實現SVGD更新\n",
    "        updated_gradients = []\n",
    "        for i in range(n):\n",
    "            updated_grad = []\n",
    "            # 修改這裡，只對可訓練參數進行迭代\n",
    "            for param_idx, param in enumerate(trainable_params):\n",
    "                grad_sum = torch.zeros_like(param)\n",
    "                for j in range(n):\n",
    "                    # 核函數: RBF核\n",
    "                    # 確保使用相同的可訓練參數\n",
    "                    param_diff = torch.sum((param - trainable_params[param_idx]) ** 2)\n",
    "                    h = param_diff.detach() / 0.01  # 帶寬\n",
    "                    kernel = torch.exp(-h)\n",
    "                    \n",
    "                    # SVGD更新\n",
    "                    grad_sum += kernel * gradients[j][param_idx]\n",
    "                \n",
    "                updated_grad.append(grad_sum / n)\n",
    "            updated_gradients.append(updated_grad)\n",
    "        \n",
    "        return updated_gradients, avg_loss\n",
    "\n",
    "    \n",
    "    def train_step(self, support_x, support_y, query_x, query_y):\n",
    "        \"\"\"執行一步元學習訓練\"\"\"\n",
    "        self.meta_optimizer.zero_grad()\n",
    "        \n",
    "        # 計算SVGD梯度\n",
    "        updated_gradients, loss = self._stein_gradient(\n",
    "            self.particles, support_x, support_y, query_x, query_y\n",
    "        )\n",
    "        \n",
    "        # 只對可訓練參數更新梯度\n",
    "        trainable_params = [p for p in self.model.parameters() if p.requires_grad]\n",
    "        \n",
    "        for param, grad in zip(trainable_params, updated_gradients[0]):\n",
    "            param.grad = grad\n",
    "        \n",
    "        self.meta_optimizer.step()\n",
    "        \n",
    "        # 更新粒子集\n",
    "        self.particles = self._clone_particles(self.model)\n",
    "        \n",
    "        return loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725ccd8",
   "metadata": {},
   "source": [
    "### 訓練流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3c168e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # 載入資料集\n",
    "    full_dataset = FoodDataset(DATA_PATH, class_to_idx, transform=train_transform)\n",
    "    n_way = 30\n",
    "    k_shot = 10\n",
    "    \n",
    "    # 訓練/驗證集劃分 (每類8:2)\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    \n",
    "    # 按類別劃分\n",
    "    for class_idx in range(len(class_names)):\n",
    "        class_indices = [i for i, (_, label) in enumerate(full_dataset.samples) if label == class_idx]\n",
    "        np.random.shuffle(class_indices)\n",
    "        split = int(0.8 * len(class_indices))\n",
    "        train_indices.extend(class_indices[:split])\n",
    "        val_indices.extend(class_indices[split:])\n",
    "    \n",
    "    # 建立訓練與驗證資料載入器\n",
    "    train_loader = DataLoader(\n",
    "        torch.utils.data.Subset(full_dataset, train_indices),\n",
    "        batch_size=n_way*k_shot,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn  # 使用MixUp/CutMix增強\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        torch.utils.data.Subset(full_dataset, val_indices),\n",
    "        batch_size=n_way*k_shot,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # 初始化模型與元學習器\n",
    "    model = get_mobilenetv2(num_classes=len(class_names))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    meta_learner = BayesianMAML(\n",
    "        model=model,\n",
    "        n_way=n_way,  # 每個元任務中的類別數\n",
    "        k_shot=k_shot,  # 每類的樣本數\n",
    "        num_particles=10,  # 貝葉斯粒子數\n",
    "        inner_lr=0.01,\n",
    "        meta_lr=0.001\n",
    "    )\n",
    "    \n",
    "    # 訓練迴圈\n",
    "    num_epochs = 50\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # 構建元學習任務（支援集和查詢集）\n",
    "            if isinstance(labels, torch.Tensor) and len(labels.shape) > 1:\n",
    "                # 處理MixUp/CutMix情況\n",
    "                one_hot_labels = labels\n",
    "                labels = torch.argmax(one_hot_labels, dim=1)\n",
    "            \n",
    "            # 簡化：使用批次的前一半作為支援集，後一半作為查詢集\n",
    "            n = len(images) // 2\n",
    "            support_x, query_x = images[:n], images[n:]\n",
    "            support_y, query_y = labels[:n], labels[n:]\n",
    "            \n",
    "            # 執行元學習步驟\n",
    "            loss = meta_learner.train_step(support_x, support_y, query_x, query_y)\n",
    "            train_loss += loss\n",
    "        \n",
    "        # 驗證\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100. * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'model.pth')\n",
    "            print(\"模型已保存!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "42aee013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 3.4698, Val Loss: 3.4499, Val Acc: 5.00%\n",
      "模型已保存!\n",
      "Epoch 2/50, Train Loss: 3.4658, Val Loss: 3.3783, Val Acc: 1.67%\n",
      "模型已保存!\n",
      "Epoch 3/50, Train Loss: 3.4311, Val Loss: 3.3203, Val Acc: 6.67%\n",
      "模型已保存!\n",
      "Epoch 4/50, Train Loss: 3.3869, Val Loss: 3.3399, Val Acc: 6.67%\n",
      "Epoch 5/50, Train Loss: 3.4153, Val Loss: 3.3511, Val Acc: 11.67%\n",
      "Epoch 6/50, Train Loss: 3.3493, Val Loss: 3.1803, Val Acc: 20.00%\n",
      "模型已保存!\n",
      "Epoch 7/50, Train Loss: 3.3141, Val Loss: 3.2430, Val Acc: 11.67%\n",
      "Epoch 8/50, Train Loss: 3.3320, Val Loss: 3.2238, Val Acc: 10.00%\n",
      "Epoch 9/50, Train Loss: 3.2500, Val Loss: 3.2223, Val Acc: 10.00%\n",
      "Epoch 10/50, Train Loss: 3.2687, Val Loss: 3.1533, Val Acc: 11.67%\n",
      "模型已保存!\n",
      "Epoch 11/50, Train Loss: 3.1088, Val Loss: 3.1952, Val Acc: 11.67%\n",
      "Epoch 12/50, Train Loss: 3.0278, Val Loss: 3.0722, Val Acc: 18.33%\n",
      "模型已保存!\n",
      "Epoch 13/50, Train Loss: 3.0583, Val Loss: 3.0975, Val Acc: 18.33%\n",
      "Epoch 14/50, Train Loss: 3.1498, Val Loss: 3.1421, Val Acc: 10.00%\n",
      "Epoch 15/50, Train Loss: 3.0245, Val Loss: 3.0475, Val Acc: 23.33%\n",
      "模型已保存!\n",
      "Epoch 16/50, Train Loss: 3.0224, Val Loss: 3.0256, Val Acc: 18.33%\n",
      "模型已保存!\n",
      "Epoch 17/50, Train Loss: 3.2310, Val Loss: 2.9071, Val Acc: 26.67%\n",
      "模型已保存!\n",
      "Epoch 18/50, Train Loss: 2.9917, Val Loss: 2.8894, Val Acc: 26.67%\n",
      "模型已保存!\n",
      "Epoch 19/50, Train Loss: 2.7751, Val Loss: 2.8984, Val Acc: 26.67%\n",
      "Epoch 20/50, Train Loss: 2.8183, Val Loss: 2.8701, Val Acc: 23.33%\n",
      "模型已保存!\n",
      "Epoch 21/50, Train Loss: 2.5602, Val Loss: 2.8130, Val Acc: 26.67%\n",
      "模型已保存!\n",
      "Epoch 22/50, Train Loss: 2.6914, Val Loss: 2.8403, Val Acc: 26.67%\n",
      "Epoch 23/50, Train Loss: 2.8095, Val Loss: 2.8817, Val Acc: 23.33%\n",
      "Epoch 24/50, Train Loss: 2.8714, Val Loss: 2.8092, Val Acc: 25.00%\n",
      "模型已保存!\n",
      "Epoch 25/50, Train Loss: 2.8612, Val Loss: 2.7325, Val Acc: 31.67%\n",
      "模型已保存!\n",
      "Epoch 26/50, Train Loss: 2.7065, Val Loss: 2.8012, Val Acc: 25.00%\n",
      "Epoch 27/50, Train Loss: 3.0440, Val Loss: 2.8288, Val Acc: 15.00%\n",
      "Epoch 28/50, Train Loss: 2.5833, Val Loss: 2.8431, Val Acc: 23.33%\n",
      "Epoch 29/50, Train Loss: 2.6453, Val Loss: 2.6800, Val Acc: 28.33%\n",
      "模型已保存!\n",
      "Epoch 30/50, Train Loss: 2.6688, Val Loss: 2.7653, Val Acc: 26.67%\n",
      "Epoch 31/50, Train Loss: 2.6087, Val Loss: 2.6273, Val Acc: 38.33%\n",
      "模型已保存!\n",
      "Epoch 32/50, Train Loss: 2.3367, Val Loss: 2.6482, Val Acc: 30.00%\n",
      "Epoch 33/50, Train Loss: 2.6937, Val Loss: 2.6272, Val Acc: 35.00%\n",
      "模型已保存!\n",
      "Epoch 34/50, Train Loss: 2.3074, Val Loss: 2.6739, Val Acc: 26.67%\n",
      "Epoch 35/50, Train Loss: 2.3008, Val Loss: 2.6239, Val Acc: 41.67%\n",
      "模型已保存!\n",
      "Epoch 36/50, Train Loss: 2.0236, Val Loss: 2.5866, Val Acc: 43.33%\n",
      "模型已保存!\n",
      "Epoch 37/50, Train Loss: 2.4766, Val Loss: 2.5203, Val Acc: 33.33%\n",
      "模型已保存!\n",
      "Epoch 38/50, Train Loss: 2.7709, Val Loss: 2.5650, Val Acc: 28.33%\n",
      "Epoch 39/50, Train Loss: 2.4046, Val Loss: 2.5995, Val Acc: 25.00%\n",
      "Epoch 40/50, Train Loss: 2.3051, Val Loss: 2.4608, Val Acc: 33.33%\n",
      "模型已保存!\n",
      "Epoch 41/50, Train Loss: 2.4799, Val Loss: 2.5908, Val Acc: 36.67%\n",
      "Epoch 42/50, Train Loss: 2.0285, Val Loss: 2.5953, Val Acc: 35.00%\n",
      "Epoch 43/50, Train Loss: 2.4529, Val Loss: 2.5356, Val Acc: 31.67%\n",
      "Epoch 44/50, Train Loss: 2.7509, Val Loss: 2.5027, Val Acc: 35.00%\n",
      "Epoch 45/50, Train Loss: 2.7574, Val Loss: 2.5630, Val Acc: 31.67%\n",
      "Epoch 46/50, Train Loss: 2.7203, Val Loss: 2.4873, Val Acc: 36.67%\n",
      "Epoch 47/50, Train Loss: 2.4810, Val Loss: 2.5250, Val Acc: 35.00%\n",
      "Epoch 48/50, Train Loss: 2.7509, Val Loss: 2.5082, Val Acc: 38.33%\n",
      "Epoch 49/50, Train Loss: 2.4518, Val Loss: 2.4668, Val Acc: 40.00%\n",
      "Epoch 50/50, Train Loss: 2.1500, Val Loss: 2.5436, Val Acc: 28.33%\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
